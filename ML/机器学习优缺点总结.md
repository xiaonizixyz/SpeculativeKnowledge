# 一、正则化算法

## 简介

正则方法是另一种方法（通常是回归方法）的拓展，该方法会基于模型复杂性对其进行惩罚，该方法喜欢相对简单能够更好泛化的模型

## 例子

- 岭回归（Ridge Regression）
- 最小绝对收缩与选择算子（LASSO）
- `GLOSSO`
- 弹性网络（Elastic Net）
- 最小角回归（Least-Angle Regression）

## 优点

- 其惩罚会减少过拟合
- 总会有解决方法

## 缺点

- 惩罚会造成欠拟合
- 很难校准

# 二、集成算法

## 简介

- 集成方法是由多个较弱的模型集成模型组，其中的模型可以单独进行训练，并且它们的预测能以某种方式结合起来做出整体预测
- 该算法的主要问题是找出哪些较弱的模型可以结合起来，以及结合的方法。该方法是一个很强大的技术集合，因此很受欢迎

## 例子

- Boosting
- Bootstrapped Aggregation（Bagging）
- AdaBoost
- 层叠泛化（Stacked Generalization）（blending）
- 梯度推进机（Gradient Boosting Machines，GBM）
- 梯度提升回归树（Gradient Boosted Regression Trees，GBRT）
- 随机森林（Random Forest）

## 优点

- 当前最先进的预测几乎都使用了算法集成。该方法比使用单个预测模型预测出来的结果要精确很多

## 缺点

- 需要大量的维护工作

# 三、决策树

## 简介

- 决策树学习使用一个决策树作为一个预测模型，它将对一个`item`(表征在分支上)观察所得映射成关于该`item`的目标值的结论（表征在叶子中）
- 树模型中的目标是可变的，可以采一组有限值，被称为分类树；在这些树结构中，叶子表示类标签，分支表示表征这些类标签的连接的特征

## 例子

- `分类和回归树（Classification and Regression Tree，CART）`
- `Iterative Dichotomiser 3（ID3）`
- `C4.5 和 C5.0（一种强大方法的两个不同版本）`

## 优点

- 容易解释
- 非参数型

## 缺点

- 趋向过拟合
- 可能或陷于局部最小值中
- 没有在线学习

# 四、回归

## 简介

回归是用于估计两种变量之间关系的统计过程。当用于分析因变量和一个、多个自变量之间的关系时，该算法能提供很多建模和分析多个变量的技巧。最常见的，回归分析可以在给定自变量的条件下估计出因变量的条件期望

## 例子

- 普通最小二乘回归（`Ordinary Least Squares Regression，OLSR`）
- 线性回归（`Linear Regression`）
- 逻辑回归（`Logistic Regression`）
- 逐步回归（`Stepwise Regression`）
- 多元自适应回归样条（`Multivariate Adaptive Regression Splines，MARS`）
- 本地散点平滑估计（`Locally Estimated Scatterplot Smoothing，LOESS`）

## 优点

- 直接、快速

## 缺点

- 要求严格的假设
- 需要处理异常值

# 五、人工神经网络

## 简介

人工神经网络是一种模式匹配，常被用于回归和分类问题，它拥有庞大的子域，由数百种算法和各类问题的变体组成

## 例子

- 感知机
- 反向传播
- `Hopfield`网络
- 径向基函数网络（`RBFN`）

## 优点

- 在语音、语义、视觉、各类游戏（如围棋）的任务中表现极好
- 算法可以快速调整，适应新的问题

## 缺点

- 需要大量数据进行训练
- 训练要求很高的硬件配置
- 模型处于黑盒状态，难以理解内部机制
- 元参数与网络拓扑选择困难

# 六、深度学习

## 简介

- 深度学习是人工神经网络的最新分支，其受益于当代硬件的快速发展。
- 众多研究者目前的主要方向集中于构建更大、更复杂的神经网络，目前有许多方法正在聚焦半监督学习问题，其中用于训练的大数据集只包含很少的标记

## 例子

- 深玻尔兹曼机（Deep Boltzmann Machine，DBM）
- Deep Belief Networks（DBN）
- 卷积神经网络（CNN）
- Stacked Auto-Encoders

## 优缺点

- 同神经网络

# 七、SVM

## 简介

- `SVM`算法可以在被输入新的事例后将其分类到2个类别中的一个，使自身成为非概率二进制线性分类器
- SVM模型将训练事例表示为空间中的点，它被映射到一幅图中，由1条明确的、尽可能宽的间隔分开以区分两个类别

## 优点

- 在非线性可分问题上表现优秀

## 缺点

- 非常难训练
- 很难解释；可解释性差

# 八、降维算法

## 简介

- 降维算法地目的在于使用较少地信息总结或描述数据
- 这一算法可用于可视化高维数据或简化接下来用于监督学习中的数据

## 例子

- 主成分分析
- 主成分回归
- 偏最小二乘回归
- Sammon映射
- 多维尺度变换
- 投影追踪
- 线性判别分析
- 混合判别分析
- 二次判别分析
- 灵活判别分析

## 优点

- 可处理大规模数据集
- 无需在数据上进行假设

## 缺点

- 不适用于非线性数据
- 可解释性差（难以理解结果的一样）

# 九、聚类算法

## 简介

- 聚类算法是指对一组目标进行分类，属于同一组的目标为划分在一组中，与其它组中的目标相比，同一组中的目标彼此更加相似

# 例子

- K-均值（K-means）
- 最大期望算法（EM）
- 分层聚类（Hierarchical Clstering）

## 优点

- 让数据变得有意义

## 缺点

- 可解释性差（结果难以解读，针对不寻常的数据组，结果可能无用）

# 十、基于实例的算法

## 简介

- 基于实例的算法（有时也称为基于记忆的学习），非明确归纳，而是将新的问题例子与训练过程中见过的例子进行对比，这些见过的例子就在存储器中
- 之所以叫基于实例的算法是因为它直接从训练实例中构建出假设。这意味着，假设的复杂度会随着数据的增长而变化；最糟的情况是，假设是一个训练项目列表，分类一个单独实例计算复杂度为O(n)

## 例子

- K最近邻`（KNN）`
- 学习向量量化`（LVQ）`
- 局部加权学习

## 优点

- 算法简单、结果易于解读

## 缺点

- 内存使用非常高
- 计算成本高
- 不可能用于高维特征空间

# 十一、贝叶斯算法

# 十二、关联规则学习算法

# 十三、图模型